{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c86094-2c1f-4f44-810c-28d0734b6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this fourth example, we will take a closer look at the model optimization.\n",
    "\n",
    "At first the optimization might seem a bit complicated, but the core of the optimization is actually rather simple.\n",
    "What makes it looks complicated is all the reporting and tracking of loss and accuracy.\n",
    "Try to step through the optimization code and see whether you can understand the various parts of the code.\n",
    "\n",
    "Here we will briefly talk about some of the design choices that are behind this pipeline.\n",
    "\n",
    "1) Typically you want to train a model many times and easily be able to compare current runs to previous runs and often on these runs are done on a remote server.\n",
    "    Our current implementation does not really offer this.\n",
    "    To get something like this we suggest the usage of some reporting framework like mlflow, tensorboard, or other such tools that automatically logs metrics and hyperparameters and allows easy visualization and comparison through an API that you can access remotely.\n",
    "    This also allows your entire team to run various models on various computers and compare them all in a central API.\n",
    "\n",
    "2) Currently, we do not use the validation dataset for anything, but typically you would want to use this to find the best model.\n",
    "\n",
    "3) In a more realistic pipeline we also need to be able to save and load the model.\n",
    "    Saving and loading models is something that needs to fit into the overall framework you run your machine learning models in.\n",
    "    For information on how saving and loading models might be done see:\n",
    "    https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86251fca-9a74-4efb-86ad-34734692589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.unet import Configuration\n",
    "\n",
    "# load configuration information\n",
    "configuration = Configuration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6496e11-b9c5-4480-9944-9575a2edf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.dataloader import load_data_wrapper\n",
    "from src.losses import select_loss_fnc\n",
    "from src.model import model_loader_wrapper\n",
    "from src.viz import eval_unlabelled_images, plot_loss_and_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f57e8-6585-4531-abfb-b61927756437",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = load_data_wrapper(**configuration)\n",
    "model = model_loader_wrapper(**configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DON'T FORGET\n",
    "# - you can use device=\"cpu\" to run everything on cpu for easier debugging - don't forget to reproduce the model and data on these devices\n",
    "# - you can wrap the whole for-loop in a `with torch.autograd.detect_anomaly():` context to get debugging feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96680d97-125b-4300-8268-4869c2c7c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will start by setting up the optimization parameters\n",
    "loss_fnc = select_loss_fnc(**configuration)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=100)\n",
    "\n",
    "data, target = next(iter(dataloaders['train']))\n",
    "data = data.to(configuration.device)\n",
    "target = target.to(configuration.device)\n",
    "\n",
    "losses = []  # keep track of our losses\n",
    "\n",
    "for i in range(100):\n",
    "    # print(i)  # sometimes it can be good to keep track of how far along we are\n",
    "\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # calculate the model's output based on the data and sigmoid to transform to range 0-1\n",
    "    output = model(data)\n",
    "    output = output.sigmoid()\n",
    "\n",
    "    # calculcate loss\n",
    "    loss = loss_fnc(output, output)\n",
    "\n",
    "    # track the loss\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # calculate gradients and update weights\n",
    "    loss.backward\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e2453",
   "metadata": {},
   "source": [
    "# Questions/exercises:\n",
    "\n",
    "1. As mentioned, the functions in optimizer.py have a lot of reporting information that are not essential for the training of a model.\n",
    "    Try to make a copy of the two functions in optimizer.py and remove all the reporting information and make the code as simple as possible.\n",
    "    Can you train your model with these new functions?\n",
    "\n",
    "2. At each epoch of the optimization, the model goes through the training dataset followed by the validation dataset.\n",
    "    As previously stated, the purpose of the validation dataset is to help find the best model, how should the validation dataset help with this? (How would you incorporate that into your optimization function?)\n",
    "3. How does the validation dataset differ from the test dataset?\n",
    "4. How come the validation loss is lower than the training loss?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
