{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c86094-2c1f-4f44-810c-28d0734b6890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this fourth example, we will take a closer look at the model optimization.\\n\\nAt first the optimization might seem a bit complicated, but the core of the optimization is actually rather simple.\\nWhat makes it looks complicated is all the reporting and tracking of loss and accuracy.\\nTry to step through the optimization code and see whether you can understand the various parts of the code.\\n\\nHere we will briefly talk about some of the design choices that are behind this pipeline.\\n\\n1) Typically you want to train a model many times and easily be able to compare current runs to previous runs and often on these runs are done on a remote server.\\n    Our current implementation does not really offer this.\\n    To get something like this we suggest the usage of some reporting framework like mlflow, tensorboard, or other such tools that automatically logs metrics and hyperparameters and allows easy visualization and comparison through an API that you can access remotely.\\n    This also allows your entire team to run various models on various computers and compare them all in a central API.\\n\\n2) Currently, we do not use the validation dataset for anything, but typically you would want to use this to find the best model.\\n\\n3) In a more realistic pipeline we also need to be able to save and load the model.\\n    Saving and loading models is something that needs to fit into the overall framework you run your machine learning models in.\\n    For information on how saving and loading models might be done see:\\n    https://pytorch.org/tutorials/beginner/saving_loading_models.html\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this fourth example, we will take a closer look at the model optimization.\n",
    "\n",
    "At first the optimization might seem a bit complicated, but the core of the optimization is actually rather simple.\n",
    "What makes it looks complicated is all the reporting and tracking of loss and accuracy.\n",
    "Try to step through the optimization code and see whether you can understand the various parts of the code.\n",
    "\n",
    "Here we will briefly talk about some of the design choices that are behind this pipeline.\n",
    "\n",
    "1) Typically you want to train a model many times and easily be able to compare current runs to previous runs and often on these runs are done on a remote server.\n",
    "    Our current implementation does not really offer this.\n",
    "    To get something like this we suggest the usage of some reporting framework like mlflow, tensorboard, or other such tools that automatically logs metrics and hyperparameters and allows easy visualization and comparison through an API that you can access remotely.\n",
    "    This also allows your entire team to run various models on various computers and compare them all in a central API.\n",
    "\n",
    "2) Currently, we do not use the validation dataset for anything, but typically you would want to use this to find the best model.\n",
    "\n",
    "3) In a more realistic pipeline we also need to be able to save and load the model.\n",
    "    Saving and loading models is something that needs to fit into the overall framework you run your machine learning models in.\n",
    "    For information on how saving and loading models might be done see:\n",
    "    https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86251fca-9a74-4efb-86ad-34734692589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.unet import Configuration\n",
    "\n",
    "# load configuration information\n",
    "configuration = Configuration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6496e11-b9c5-4480-9944-9575a2edf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.dataloader import load_data_wrapper\n",
    "from src.losses import select_loss_fnc\n",
    "from src.model import model_loader_wrapper\n",
    "from src.viz import eval_unlabelled_images, plot_loss_and_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522f57e8-6585-4531-abfb-b61927756437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet loaded, containing 31.04M trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "dataloaders = load_data_wrapper(**configuration)\n",
    "model = model_loader_wrapper(**configuration)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=configuration['lr'])\n",
    "loss_fnc = select_loss_fnc(**configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96680d97-125b-4300-8268-4869c2c7c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def optimize_model(model, dataloaders, optimizer, loss_fnc, epochs, **kwargs):\n",
    "    \"\"\"\n",
    "    Simple tracking of model optimization.\n",
    "    \"\"\"\n",
    "    dataset_types = ['train', 'val']\n",
    "    assert set(dataset_types).issubset(dataloaders), f'dataloaders are expected to contain {dataset_types}'\n",
    "    losses = {dataset_type: [] for dataset_type in dataset_types}\n",
    "    accuracies = {dataset_type: [] for dataset_type in dataset_types}\n",
    "\n",
    "    for epoch in (pbar := tqdm(range(epochs),desc=f\"Training...\")):\n",
    "        for dataset_type in dataset_types:\n",
    "            loss, accuracy = train_or_eval_model(model, dataloaders[dataset_type], optimizer, loss_fnc, is_training=dataset_type=='train')\n",
    "            losses[dataset_type].append(loss)\n",
    "            accuracies[dataset_type].append(accuracy)\n",
    "        pbar.set_postfix(loss_train=losses['train'][-1], loss_val=losses['val'][-1], accuracy_train = accuracies['train'][-1], accuracy_val=accuracies['val'][-1])\n",
    "    return losses, accuracies\n",
    "\n",
    "def train_or_eval_model(model, dataloader, optimizer, loss_fnc, is_training):\n",
    "    \"\"\"\n",
    "    Runs a dataloader through a model.\n",
    "    Supports both training and evaluation mode.\n",
    "    \"\"\"\n",
    "    model.train(is_training)\n",
    "    torch.set_grad_enabled(is_training)\n",
    "    loss_agg = 0.0\n",
    "    true_predictions = 0\n",
    "    predictions = 0\n",
    "    assert len(dataloader) > 0, f\"The dataloader should contain at least one batch of samples.\"\n",
    "    for i, (x,target) in enumerate(dataloader):\n",
    "        prediction_prob = model(x)\n",
    "        loss = loss_fnc(prediction_prob,target)\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_agg += loss.item()\n",
    "        prediction = torch.argmax(prediction_prob,dim=1)\n",
    "        true_predictions += (prediction == target).sum().item()\n",
    "        predictions += target.shape[0]\n",
    "\n",
    "    accuracy_average = true_predictions / predictions\n",
    "    loss_average = loss_agg / predictions\n",
    "    return loss_average, accuracy_average\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9745c116",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_399055/1831739299.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fnc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_399055/764909669.py\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(model, dataloaders, optimizer, loss_fnc, epochs, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_types\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_or_eval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fnc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "losses, accuracies = optimize_model(model, dataloaders, optimizer, loss_fnc, **configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e78bcd-1fa4-4737-9741-d6429934f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_accuracy(losses, accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e2453",
   "metadata": {},
   "source": [
    "# Questions/exercises:\n",
    "\n",
    "1. As mentioned, the functions in optimizer.py have a lot of reporting information that are not essential for the training of a model.\n",
    "    Try to make a copy of the two functions in optimizer.py and remove all the reporting information and make the code as simple as possible.\n",
    "    Can you train your model with these new functions?\n",
    "\n",
    "2. At each epoch of the optimization, the model goes through the training dataset followed by the validation dataset.\n",
    "    As previously stated, the purpose of the validation dataset is to help find the best model, how should the validation dataset help with this? (How would you incorporate that into your optimization function?)\n",
    "3. How does the validation dataset differ from the test dataset?\n",
    "4. How come the validation loss is lower than the training loss?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
