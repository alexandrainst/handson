{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c86094-2c1f-4f44-810c-28d0734b6890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this third example, we will take a closer look at the model.\\n\\nThere exist a wealth of different models all with various strengths and weaknesses.\\n\\nDiving into model details is beyond the scope of this workshop,\\nbut suffice to say that model architecture is constantly evolving and unless you are an expert you are likely best off just using some well performing neural network for a problem similar to the one you are interested in.\\n\\nCommon to all neural networks is that they consist of some amount of trainable parameters and in general the more parameters a model has, the more memory it requires to train/run and the longer it takes.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this third example, we will take a closer look at the model.\n",
    "\n",
    "There exist a wealth of different models all with various strengths and weaknesses.\n",
    "\n",
    "Diving into model details is beyond the scope of this workshop,\n",
    "but suffice to say that model architecture is constantly evolving and unless you are an expert you are likely best off just using some well performing neural network for a problem similar to the one you are interested in.\n",
    "\n",
    "Common to all neural networks is that they consist of some amount of trainable parameters and in general the more parameters a model has, the more memory it requires to train/run and the longer it takes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86251fca-9a74-4efb-86ad-34734692589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.efficient_net_b2_pretrained import Configuration\n",
    "# load configuration information\n",
    "configuration = Configuration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6496e11-b9c5-4480-9944-9575a2edf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\"\"\"\n",
    "In this project we have provided a simple U-net convolutional model, as well as a few models from torchvisions modelhub.\n",
    "\"\"\"\n",
    "\n",
    "def model_loader_wrapper(model_name, model_weights=None, device='cpu', **kwargs):\n",
    "    \"\"\"\n",
    "    Selects the model we want to use.\n",
    "\n",
    "    Note that we have both premade/pretrained models as well as our own custom models in here.\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name == \"resnet50\":\n",
    "        model = torchvision.models.resnet50(weights=model_weights)\n",
    "    elif model_name == \"efficient_net_b2\":\n",
    "        model = torchvision.models.efficientnet_b2(weights=model_weights)\n",
    "        model.classifier[1] = torch.nn.Linear(1408,2,bias=True)\n",
    "    elif model_name == 'unet':\n",
    "        model = UNet()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{model_name} has not been implemented.\")\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'{model_name} loaded, containing {total_params/1000000:2.2f}M trainable parameters.')\n",
    "    model.to(device=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x2 = self.up_scale(x2)\n",
    "\n",
    "        diffY = x1.size()[2] - x2.size()[2]\n",
    "        diffX = x1.size()[3] - x2.size()[3]\n",
    "\n",
    "        x2 = torch.functional.pad(x2, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownLayer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DownLayer, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.pool(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpLayer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpLayer, self).__init__()\n",
    "        self.up = Up(in_ch, out_ch)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        a = self.up(x1, x2)\n",
    "        x = self.conv(a)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, dimensions=2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = DoubleConv(3, 64)\n",
    "        self.down1 = DownLayer(64, 128)\n",
    "        self.down2 = DownLayer(128, 256)\n",
    "        self.down3 = DownLayer(256, 512)\n",
    "        self.down4 = DownLayer(512, 1024)\n",
    "        self.up1 = UpLayer(1024, 512)\n",
    "        self.up2 = UpLayer(512, 256)\n",
    "        self.up3 = UpLayer(256, 128)\n",
    "        self.up4 = UpLayer(128, 64)\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Dropout(p=0.3, inplace=True), torch.nn.Linear(64,dimensions,bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x1_up = self.up1(x4, x5)\n",
    "        x2_up = self.up2(x3, x1_up)\n",
    "        x3_up = self.up3(x2, x2_up)\n",
    "        x4_up = self.up4(x1, x3_up)\n",
    "        y = self.avgpool(x4_up)\n",
    "        output = self.classifier(y[:,:,0,0])\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522f57e8-6585-4531-abfb-b61927756437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficient_net_b2 loaded, containing 7.70M trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader import load_data_wrapper\n",
    "from src.losses import select_loss_fnc\n",
    "from src.optimizer import optimize_model\n",
    "from src.viz import eval_unlabelled_images, plot_loss_and_accuracy\n",
    "\n",
    "\n",
    "dataloaders = load_data_wrapper(**configuration)\n",
    "model = model_loader_wrapper(**configuration) # Here we build our model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=configuration['lr'])\n",
    "loss_fnc = select_loss_fnc(**configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a63deb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in /home/ohjerm/.local/lib/python3.10/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_367788/598670853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# for now, we will focus on the summary:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "\"\"\"\n",
    "Next we need to train the model.\n",
    "The overall training will be the focus of the 4th exercise, so we won't dive into that yet, but we will take a quick step inside the training and focus on how the data propagates through the model.\n",
    "\"\"\"\n",
    "\n",
    "# this is how we would train the model\n",
    "# losses, accuracies = optimize_model(model, dataloaders, optimizer, loss_fnc, **configuration)\n",
    "\n",
    "# for now, we will focus on the summary:\n",
    "summary(model, (3, 256, 256), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e2453",
   "metadata": {},
   "source": [
    "# A few questions to consider:\n",
    "\n",
    "1. Based on the shape of the data as it changed through the forward function of the model what do you think is happening?\n",
    "2. When we use a pretrained model and change the last layers to fit our particular needs, do we then need to retrain the whole model?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
